{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d7663b-cfbc-4324-bef9-efe5ad51c1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MESSY EMPLOYEE DATA ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_id</th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>join_date</th>\n",
       "      <th>performance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John</td>\n",
       "      <td>IT</td>\n",
       "      <td>75000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>HR</td>\n",
       "      <td>65000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Mike</td>\n",
       "      <td>IT</td>\n",
       "      <td>80000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-11-10</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Finance</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>60000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>Emma</td>\n",
       "      <td>IT</td>\n",
       "      <td>85000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Alex</td>\n",
       "      <td>HR</td>\n",
       "      <td>70000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>Finance</td>\n",
       "      <td>95000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>John</td>\n",
       "      <td>IT</td>\n",
       "      <td>75000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>None</td>\n",
       "      <td>Sales</td>\n",
       "      <td>50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_id    name department salary  experience_yrs   join_date  \\\n",
       "0     101    John         IT  75000             3.0  2020-01-15   \n",
       "1     102   Sarah         HR  65000             2.0  2021-03-20   \n",
       "2     103    Mike         IT  80000             5.0  2018-11-10   \n",
       "3     104    Lisa    Finance   None             8.0        None   \n",
       "4     105     Tom  Marketing  60000             1.0  2022-08-15   \n",
       "5     106    Emma         IT  85000             6.0  2017-09-05   \n",
       "6     107    Alex         HR  70000             2.0  2021-07-30   \n",
       "7     108  Rachel    Finance  95000            10.0  2013-12-10   \n",
       "8     109    John         IT  75000             3.0  2020-01-15   \n",
       "9     110    None      Sales  50000             NaN  2023-01-01   \n",
       "\n",
       "   performance_score  \n",
       "0               85.0  \n",
       "1               92.0  \n",
       "2               78.0  \n",
       "3               88.0  \n",
       "4                NaN  \n",
       "5               95.0  \n",
       "6               90.0  \n",
       "7               87.0  \n",
       "8               85.0  \n",
       "9               82.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# This is what real data often looks like!\n",
    "messy_employees = {\n",
    "    'emp_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    'name': ['John', 'Sarah', 'Mike', 'Lisa', 'Tom', 'Emma', 'Alex', 'Rachel', 'John', None],\n",
    "    'department': ['IT', 'HR', 'IT', 'Finance', 'Marketing', 'IT', 'HR', 'Finance', 'IT', 'Sales'],\n",
    "    'salary': ['75000', '65000', '80000', None, '60000', '85000', '70000', '95000', '75000', '50000'],\n",
    "    'experience_yrs': [3, 2, 5, 8, 1, 6, 2, 10, 3, None],\n",
    "    'join_date': ['2020-01-15', '2021-03-20', '2018-11-10', None, '2022-08-15', \n",
    "                  '2017-09-05', '2021-07-30', '2013-12-10', '2020-01-15', '2023-01-01'],\n",
    "    'performance_score': [85, 92, 78, 88, None, 95, 90, 87, 85, 82]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(messy_employees)\n",
    "print(\"=== MESSY EMPLOYEE DATA ===\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4522e-8f28-4426-8639-a3786be041ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¥ LEVEL 2 PRACTICE QUESTIONS\n",
    "Set 1: Missing Value Management\n",
    "Q1: How many missing values are in each column?\n",
    "Q2: Fill missing salaries with the average salary of other employees\n",
    "Q3: Remove any rows where both 'name' AND 'department' are missing\n",
    "Q4: Fill missing performance scores with the median value\n",
    "\n",
    "Set 2: Data Quality & Consistency\n",
    "Q5: Find and remove duplicate employee records\n",
    "Q6: Convert 'salary' column from string to integer data type\n",
    "Q7: Convert 'join_date' to proper datetime format\n",
    "Q8: Create a clean version where all missing values are handled appropriately\n",
    "\n",
    "Set 3: Advanced Challenges\n",
    "Q9: Which department has the most missing data?\n",
    "Q10: Create a new column 'is_senior' (True if experience > 5 years, False otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ce43f5-4945-4fda-a17a-9e30010d6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_id               0\n",
      "name                 1\n",
      "department           0\n",
      "salary               1\n",
      "experience_yrs       1\n",
      "join_date            1\n",
      "performance_score    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_employees = df.isnull().sum()\n",
    "print(missing_employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e5dc68-ec2a-45a5-bbbd-061e4bcd2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average salary to use: $72,777.78\n",
      "   emp_id    name department        salary  experience_yrs   join_date  \\\n",
      "0     101    John         IT  75000.000000             3.0  2020-01-15   \n",
      "1     102   Sarah         HR  65000.000000             2.0  2021-03-20   \n",
      "2     103    Mike         IT  80000.000000             5.0  2018-11-10   \n",
      "3     104    Lisa    Finance  72777.777778             8.0        None   \n",
      "4     105     Tom  Marketing  60000.000000             1.0  2022-08-15   \n",
      "5     106    Emma         IT  85000.000000             6.0  2017-09-05   \n",
      "6     107    Alex         HR  70000.000000             2.0  2021-07-30   \n",
      "7     108  Rachel    Finance  95000.000000            10.0  2013-12-10   \n",
      "8     109    John         IT  75000.000000             3.0  2020-01-15   \n",
      "9     110    None      Sales  50000.000000             NaN  2023-01-01   \n",
      "\n",
      "   performance_score  \n",
      "0               85.0  \n",
      "1               92.0  \n",
      "2               78.0  \n",
      "3               88.0  \n",
      "4                NaN  \n",
      "5               95.0  \n",
      "6               90.0  \n",
      "7               87.0  \n",
      "8               85.0  \n",
      "9               82.0  \n"
     ]
    }
   ],
   "source": [
    "df['salary'] = df['salary'].astype(float)\n",
    "\n",
    "average_salary = df['salary'].mean()\n",
    "print(f\"Average salary to use: ${average_salary:,.2f}\")\n",
    "\n",
    "missing_salaries = df.fillna({\"salary\": average_salary})\n",
    "print(missing_salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bb61ae9-5678-43ff-96f9-330a41673305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before your operation:\n",
      "DataFrame shape: (10, 7)\n",
      "Missing names: 1\n",
      "Missing departments: 0\n",
      "\n",
      "After your dropna(): (7, 7)\n",
      "Rows with both name AND department missing: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Before your operation:\")\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Missing names: {df['name'].isnull().sum()}\")\n",
    "print(f\"Missing departments: {df['department'].isnull().sum()}\")\n",
    "\n",
    "row_remove = df.dropna()\n",
    "print(f\"\\nAfter your dropna(): {row_remove.shape}\")\n",
    "\n",
    "# Check if any rows have both name AND department missing\n",
    "both_missing = df[df['name'].isnull() & df['department'].isnull()]\n",
    "print(f\"Rows with both name AND department missing: {len(both_missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07dcfbfc-fc66-4cd5-91ce-6ccba3668d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emp_id    name department salary  experience_yrs   join_date  \\\n",
      "0     101    John         IT  75000             3.0  2020-01-15   \n",
      "1     102   Sarah         HR  65000             2.0  2021-03-20   \n",
      "2     103    Mike         IT  80000             5.0  2018-11-10   \n",
      "3     104    Lisa    Finance   None             8.0        None   \n",
      "4     105     Tom  Marketing  60000             1.0  2022-08-15   \n",
      "5     106    Emma         IT  85000             6.0  2017-09-05   \n",
      "6     107    Alex         HR  70000             2.0  2021-07-30   \n",
      "7     108  Rachel    Finance  95000            10.0  2013-12-10   \n",
      "8     109    John         IT  75000             3.0  2020-01-15   \n",
      "9     110    None      Sales  50000             NaN  2023-01-01   \n",
      "\n",
      "   performance_score  \n",
      "0               85.0  \n",
      "1               92.0  \n",
      "2               78.0  \n",
      "3               88.0  \n",
      "4               87.0  \n",
      "5               95.0  \n",
      "6               90.0  \n",
      "7               87.0  \n",
      "8               85.0  \n",
      "9               82.0  \n"
     ]
    }
   ],
   "source": [
    "df['performance_score'] = df['performance_score'].astype(float)\n",
    "\n",
    "median_value = df['performance_score'].median()\n",
    "missing_perf = df.fillna({'performance_score': median_value})\n",
    "print(missing_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa30f1ca-2b0c-471c-b3c7-69f51552b544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Q5: DUPLICATE DETECTION ===\n",
      "Total duplicate rows: 0\n",
      "\n",
      "Duplicate rows:\n",
      "Empty DataFrame\n",
      "Columns: [emp_id, name, department, salary, experience_yrs, join_date, performance_score]\n",
      "Index: []\n",
      "\n",
      "Employees with same name AND salary: 2\n",
      "   emp_id  name department   salary  experience_yrs   join_date  \\\n",
      "0     101  John         IT  75000.0             3.0  2020-01-15   \n",
      "8     109  John         IT  75000.0             3.0  2020-01-15   \n",
      "\n",
      "   performance_score  \n",
      "0               85.0  \n",
      "8               85.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== Q5: DUPLICATE DETECTION ===\")\n",
    "\n",
    "# Find all duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "print(f\"Total duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "# Show the actual duplicate rows\n",
    "print(\"\\nDuplicate rows:\")\n",
    "print(df[duplicates])\n",
    "\n",
    "# Find duplicates based on specific columns (like employee ID or name)\n",
    "duplicate_names = df.duplicated(subset=['name', 'salary'], keep=False)\n",
    "print(f\"\\nEmployees with same name AND salary: {duplicate_names.sum()}\")\n",
    "print(df[duplicate_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b67cd40-1ef8-4c83-a927-e4ce9fae568e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Convert to integer\n",
    "df['salary'] = df['salary'].fillna(0).astype(int)\n",
    "\n",
    "# Check current data type\n",
    "print(df['salary'].dtype)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4deb642-1d75-4634-94a4-2ce65b0e1240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before - join_date dtype: object\n",
      "Sample dates: ['2020-01-15', '2021-03-20', '2018-11-10']\n",
      "\n",
      "After conversion:\n",
      "emp_id                        int64\n",
      "name                         object\n",
      "department                   object\n",
      "salary                        int64\n",
      "experience_yrs              float64\n",
      "join_date            datetime64[ns]\n",
      "performance_score           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Q7: Convert 'join_date' to proper datetime format\n",
    "\n",
    "print(f\"Before - join_date dtype: {df['join_date'].dtype}\")\n",
    "print(f\"Sample dates: {df['join_date'].head(3).tolist()}\")\n",
    "\n",
    "# Convert to proper datetime\n",
    "df['join_date'] = pd.to_datetime(df['join_date'])\n",
    "print(\"\\nAfter conversion:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c7936cd-3513-4bb6-8271-3a130bd55a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   emp_id             10 non-null     int64         \n",
      " 1   name               9 non-null      object        \n",
      " 2   department         10 non-null     object        \n",
      " 3   salary             10 non-null     int64         \n",
      " 4   experience_yrs     9 non-null      float64       \n",
      " 5   join_date          9 non-null      datetime64[ns]\n",
      " 6   performance_score  9 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(2)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "#Q8: Create a clean version where all missing values are handled appropriately\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8fabad5-7f92-4c77-b359-750dcadf8178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MY IMPROVED Q8 SOLUTION ===\n",
      "Missing values remaining: 1\n",
      "CLEAN DATASET READY! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MY IMPROVED Q8 SOLUTION ===\")\n",
    "\n",
    "# Create clean copy\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Step 1: Handle missing names\n",
    "df_clean['name'] = df_clean['name'].fillna('Unknown')\n",
    "\n",
    "# Step 2: Handle missing experience years  \n",
    "exp_median = df_clean['experience_yrs'].median()  # Your turn!\n",
    "df_clean['experience_yrs'] = df_clean['experience_yrs'].fillna(exp_median)  # Your turn!\n",
    "\n",
    "# Step 3: Handle missing join dates\n",
    "df_clean['join_date'] = df_clean['join_date'].fillna('2020-01-01')  # Your turn!\n",
    "\n",
    "# Step 4: Remove duplicates\n",
    "df_clean = df_clean.drop_duplicates()  # Your turn!\n",
    "\n",
    "# Final check\n",
    "print(f\"Missing values remaining: {df_clean.isnull().sum().sum()}\")\n",
    "print(\"CLEAN DATASET READY! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a0686-fd8c-424e-bbb5-cab24987720c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
